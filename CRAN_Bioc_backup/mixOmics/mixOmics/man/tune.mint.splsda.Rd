% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune.mint.splsda.R
\name{tune.mint.splsda}
\alias{tune.mint.splsda}
\title{Estimate the parameters of mint.splsda method}
\usage{
tune.mint.splsda(
  X,
  Y,
  ncomp = 1,
  study,
  test.keepX = c(5, 10, 15),
  already.tested.X,
  dist = c("max.dist", "centroids.dist", "mahalanobis.dist"),
  measure = c("BER", "overall"),
  auc = FALSE,
  progressBar = FALSE,
  scale = TRUE,
  tol = 1e-06,
  max.iter = 100,
  near.zero.var = FALSE,
  light.output = TRUE,
  signif.threshold = 0.01
)
}
\arguments{
\item{X}{numeric matrix of predictors. \code{NA}s are allowed.}

\item{Y}{Outcome. Numeric vector or matrix of responses (for multi-response
models)}

\item{ncomp}{Number of components to include in the model (see Details).
Default to 1}

\item{study}{grouping factor indicating which samples are from the same
study}

\item{test.keepX}{numeric vector for the different number of variables to
test from the \eqn{X} data set}

\item{already.tested.X}{if \code{ncomp > 1} Numeric vector indicating the
number of variables to select from the \eqn{X} data set on the firsts
components}

\item{dist}{only applies to an object inheriting from \code{"plsda"} or
\code{"splsda"} to evaluate the classification performance of the model.
Should be a subset of \code{"max.dist"}, \code{"centroids.dist"},
\code{"mahalanobis.dist"}. Default is \code{"all"}. See
\code{\link{predict}}.}

\item{measure}{Two misclassification measure are available: overall
misclassification error \code{overall} or the Balanced Error Rate \code{BER}}

\item{auc}{if \code{TRUE} calculate the Area Under the Curve (AUC)
performance of the model.}

\item{progressBar}{by default set to \code{TRUE} to output the progress bar
of the computation.}

\item{scale}{Logical. If scale = TRUE, each block is standardized to zero
means and unit variances (default: TRUE)}

\item{tol}{Convergence stopping value.}

\item{max.iter}{integer, the maximum number of iterations.}

\item{near.zero.var}{Logical, see the internal \code{\link{nearZeroVar}}
function (should be set to TRUE in particular for data with many zero
values). Default value is FALSE}

\item{light.output}{if set to FALSE, the prediction/classification of each
sample for each of \code{test.keepX} and each comp is returned.}

\item{signif.threshold}{numeric between 0 and 1 indicating the significance
threshold required for improvement in error rate of the components. Default
to 0.01.}
}
\value{
The returned value is a list with components:
\item{error.rate}{returns the prediction error for each \code{test.keepX} on
each component, averaged across all repeats and subsampling folds. Standard
deviation is also output. All error rates are also available as a list.}
\item{choice.keepX}{returns the number of variables selected (optimal keepX)
on each component.} \item{choice.ncomp}{returns the optimal number of
components for the model fitted with \code{$choice.keepX} }
\item{error.rate.class}{returns the error rate for each level of \code{Y}
and for each component computed with the optimal keepX}

\item{predict}{Prediction values for each sample, each \code{test.keepX} and
each comp.} \item{class}{Predicted class for each sample, each
\code{test.keepX} and each comp.}
}
\description{
Computes Leave-One-Group-Out-Cross-Validation (LOGOCV) scores on a
user-input grid to determine optimal values for the sparsity parameters in
\code{mint.splsda}.
}
\details{
This function performs a Leave-One-Group-Out-Cross-Validation (LOGOCV),
where each of \code{study} is left out once. It returns a list of variables
of \code{X} that were selected on each of the \code{ncomp} components. Then,
a \code{\link{mint.splsda}} can be performed with \code{keepX} set as the
output \code{choice.keepX}.

All component \eqn{1:\code{ncomp}} are tuned, except the first ones for
which a \code{already.tested.X} is provided. See examples below.

The function outputs the optimal number of components that achieve the best
performance based on the overall error rate or BER. The assessment is
data-driven and similar to the process detailed in (Rohart et al., 2016),
where one-sided t-tests assess whether there is a gain in performance when
adding a component to the model. Our experience has shown that in most case,
the optimal number of components is the number of categories in \code{Y} -
1, but it is worth tuning a few extra components to check (see our website
and case studies for more details).

BER is appropriate in case of an unbalanced number of samples per class as
it calculates the average proportion of wrongly classified samples in each
class, weighted by the number of samples in each class. BER is less biased
towards majority classes during the performance assessment.

More details about the prediction distances in \code{?predict} and the
supplemental material of the mixOmics article (Rohart et al. 2017).
}
\examples{
data(stemcells)
data = stemcells$gene
type.id = stemcells$celltype
exp = stemcells$study

res = mint.splsda(X=data,Y=type.id,ncomp=3,keepX=c(10,5,15),study=exp)
out = tune.mint.splsda(X=data,Y=type.id,ncomp=2,near.zero.var=FALSE,
study=exp,test.keepX=seq(1,10,1))

out$choice.ncomp
out$choice.keepX

\dontrun{

out = tune.mint.splsda(X=data,Y=type.id,ncomp=2,near.zero.var=FALSE,
study=exp,test.keepX=seq(1,10,1))
out$choice.keepX

## only tune component 2 and keeping 10 genes on comp1
out = tune.mint.splsda(X=data,Y=type.id,ncomp=2, study=exp,
already.tested.X = c(10),
test.keepX=seq(1,10,1))
out$choice.keepX

}
}
\references{
Rohart F, Eslami A, Matigian, N, Bougeard S, Lê Cao K-A (2017).
MINT: A multivariate integrative approach to identify a reproducible
biomarker signature across multiple experiments and platforms. BMC
Bioinformatics 18:128.

mixOmics article:

Rohart F, Gautier B, Singh A, Lê Cao K-A. mixOmics: an R package for 'omics
feature selection and multiple data integration. PLoS Comput Biol 13(11):
e1005752
}
\seealso{
\code{\link{mint.splsda}} and http://www.mixOmics.org for more
details.
}
\author{
Florian Rohart, Al J Abadi
}
\keyword{dplot}
\keyword{multivariate}
