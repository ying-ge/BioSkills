<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Saving and serializing models</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Saving and serializing models</h1>



<blockquote>
<p>This tutorial is an R translation of <a href="https://www.tensorflow.org/tutorials/keras/save_and_load">this
page</a> available in the official TensorFlow documentation.</p>
</blockquote>
<p>The first part of this guide covers saving and serialization for
Sequential models and models built using the Functional API. The saving
and serialization APIs are the exact same for both of these types of
models.</p>
<p>Saving for custom subclasses of Model is covered in the section
“Saving Subclassed Models”. The APIs in this case are slightly different
than for Sequential or Functional models.</p>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>For Sequential Models and models built using the Functional API
use:</p>
<ul>
<li><p><code>save_model_hdf5()</code>/<code>load_model_hdf5()</code> to
save the entire model to disk, including the <code>optimizer</code>
state. You can also use
<code>save_model_tf</code>/<code>load_model_tf</code> to save the entire
model to the SavedModel format.</p></li>
<li><p><code>get_config()</code>/<code>from_config()</code> to load only
the model architecture into an R object.</p></li>
<li><p><code>model_to_json()</code>/<code>model_from_json()</code> to
save only the architecture of the model to a single string - useful for
saving the architecture to disk. You can also use
<code>model_to_yaml()</code>/<code>model_from_yaml()</code> to save the
architecture.</p></li>
<li><p><code>save_model_weights_hdf5()</code>/<code>load_model_weights_hdf5()</code>
if you want to save only the model weights to disk in the
<code>hdf5</code> format. You can also use
<code>save_model_weights_tf()</code>/<code>load_model_weights_tf()</code>
to save the weights in the SavedModel format.</p></li>
</ul>
<p><strong>Note</strong> you can use a combination of
<code>model_to_json()</code> and <code>save_model_weights_hdf5()</code>
to save both the architecture and the weights. In this case the
optimizer state is not saved.</p>
<p>For custom models use:</p>
<ul>
<li><code>save_model_weights_tf()</code> or
<code>save_model_weights_hdf5()</code> to save the model weights.
Usually for custom models, the architecture must be recreated using
code.</li>
</ul>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(keras)</span></code></pre></div>
</div>
<div id="saving-sequential-models-or-functional-models" class="section level2">
<h2>Saving Sequential Models or Functional models</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>inputs <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="dv">784</span>, <span class="at">name =</span> <span class="st">&quot;digits&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>outputs <span class="ot">&lt;-</span> inputs <span class="sc">%&gt;%</span> </span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">name =</span> <span class="st">&quot;dense_1&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">name =</span> <span class="st">&quot;dense_2&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>, <span class="at">name =</span> <span class="st">&quot;predictions&quot;</span>)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(inputs, outputs) </span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<p>Optionally, let’s train this model, just so it has weight values to
save, as well as an an optimizer state. Of course, you can save models
you’ve never trained, too, but obviously that’s less interesting.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">c</span>(<span class="fu">c</span>(x_train, y_train), <span class="fu">c</span>(x_test, y_test)) <span class="sc">%&lt;-%</span> <span class="fu">dataset_mnist</span>()</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> x_train <span class="sc">%&gt;%</span> <span class="fu">array_reshape</span>(<span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">60000</span>, <span class="dv">784</span>))<span class="sc">/</span><span class="dv">255</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>x_test <span class="ot">&lt;-</span> x_test <span class="sc">%&gt;%</span> <span class="fu">array_reshape</span>(<span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">10000</span>, <span class="dv">784</span>))<span class="sc">/</span><span class="dv">255</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(<span class="at">loss =</span> <span class="st">&quot;sparse_categorical_crossentropy&quot;</span>,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>                  <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>())</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>history <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">64</span>, <span class="at">epochs =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Save predictions for future checks</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, x_test)</span></code></pre></div>
<div id="whole-model-saving" class="section level3">
<h3>Whole-model saving</h3>
<p>You can save a model built with the Functional API into a single
file. You can later recreate the same model from this file, even if you
no longer have access to the code that created the model.</p>
<p>This file includes:</p>
<ul>
<li>The model’s architecture</li>
<li>The model’s weight values (which were learned during training)</li>
<li>The model’s training config (what you passed to compile), if
any</li>
<li>The optimizer and its state, if any (this enables you to restart
training where you left off)</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Save the model</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">save_model_hdf5</span>(model, <span class="st">&quot;model.h5&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># Recreate the exact same model purely from the file</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>new_model <span class="ot">&lt;-</span> <span class="fu">load_model_hdf5</span>(<span class="st">&quot;model.h5&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Check that the state is preserved</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(new_model, x_test)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="fu">all.equal</span>(predictions, new_predictions)</span></code></pre></div>
<p>Note that the optimizer state is preserved as well so you can resume
training where you left off.</p>
</div>
<div id="export-to-savedmodel" class="section level3">
<h3>Export to SavedModel</h3>
<p>You can also export a whole model to the TensorFlow SavedModel
format. SavedModel is a standalone serialization format for Tensorflow
objects, supported by TensorFlow serving as well as TensorFlow
implementations other than Python. Note that <code>save_model_tf</code>
is only available for TensorFlow version greater than 1.14.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Export the model to a SavedModel</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="fu">save_model_tf</span>(model, <span class="st">&quot;model/&quot;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co"># Recreate the exact same model</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>new_model <span class="ot">&lt;-</span> <span class="fu">load_model_tf</span>(<span class="st">&quot;model/&quot;</span>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="co"># Check that the state is preserved</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(new_model, x_test)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="fu">all.equal</span>(predictions, new_predictions)</span></code></pre></div>
<p>Note that the optimizer state is preserved as well so you can resume
training where you left off.</p>
<p>The <code>SavedModel</code> files that were created contain:</p>
<ul>
<li>A TensorFlow checkpoint containing the model weights.</li>
<li>A SavedModel proto containing the underlying Tensorflow graph.
Separate graphs are saved for prediction (serving), train, and
evaluation. If the model wasn’t compiled before, then only the inference
graph gets exported.</li>
<li>The model’s architecture config, if available.</li>
</ul>
<p>You can also use the <code>export_savedmodel</code> function to
export models but those models can not be loaded as Keras models again.
Models exported using <code>exported_savedmodels</code> can be used for
prediction though.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">export_savedmodel</span>(model, <span class="st">&quot;savedmodel/&quot;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> tfdeploy<span class="sc">::</span><span class="fu">predict_savedmodel</span>(x_test, <span class="st">&quot;savedmodel/&quot;</span>)</span></code></pre></div>
<p><strong>Note</strong> Exporting with <code>export_savedmodel</code>
sets learning phase to 0 so you need to restart R and re-build the model
before doing additional training.</p>
</div>
<div id="architecture-only-saving" class="section level3">
<h3>Architecture-only saving</h3>
<p>Sometimes, you are only interested in the architecture of the model,
and you don’t need to save the weight values or the optimizer. In this
case, you can retrieve the “config” of the model via the get_config()
method. The config is a named list that enables you to recreate the same
model – initialized from scratch, without any of the information learned
previously during training.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>config <span class="ot">&lt;-</span> <span class="fu">get_config</span>(model)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>reinitialized_model <span class="ot">&lt;-</span> <span class="fu">from_config</span>(config)</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Note that the model state is not preserved! We only saved the architecture.</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(reinitialized_model, x_test)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="fu">all.equal</span>(predictions, new_predictions)</span></code></pre></div>
<p>You can alternatively use <code>model_to_json()</code> and
<code>model_from_json()</code>, which uses a JSON string to store the
config instead of a named list. This is useful to save the config to
disk.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>json_config <span class="ot">&lt;-</span> <span class="fu">model_to_json</span>(model)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>reinitialized_model <span class="ot">&lt;-</span> <span class="fu">model_from_json</span>(json_config)</span></code></pre></div>
</div>
<div id="weights-only-saving" class="section level3">
<h3>Weights-only saving</h3>
<p>Sometimes, you are only interested in the state of the model – its
weights values – and not in the architecture. In this case, you can
retrieve the weights values as a list of arrays via
<code>get_weights()</code>, and set the state of the model via
<code>set_weights</code>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>weights <span class="ot">&lt;-</span> <span class="fu">get_weights</span>(model)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">set_weights</span>(reinitialized_model, weights)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(reinitialized_model, x_test)</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="fu">all.equal</span>(predictions, new_predictions)</span></code></pre></div>
<p>You can combine <code>get_config()</code>/<code>from_config()</code>
and <code>get_weights()</code>/<code>set_weights()</code> to recreate
your model in the same state. However, unlike
<code>save_model_hdf5</code>, this will not include the training config
and the optimizer. You would have to call <code>compile()</code> again
before using the model for training.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>config <span class="ot">&lt;-</span> <span class="fu">get_config</span>(model)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>weights <span class="ot">&lt;-</span> <span class="fu">get_weights</span>(model)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>new_model <span class="ot">&lt;-</span> <span class="fu">from_config</span>(config)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="fu">set_weights</span>(new_model, weights)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co"># Check that the state is preserved</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(new_model, x_test)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="fu">all.equal</span>(predictions, new_predictions)</span></code></pre></div>
<p>Note that the optimizer was not preserved, so the model should be
compiled anew before training (and the optimizer will start from a blank
state).</p>
<p>The save-to-disk alternative to <code>get_weights()</code> and
<code>set_weights(weights)</code> is <code>save_weights(fpath)</code>
and <code>load_weights(fpath)</code>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Save JSON config to disk</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>json_config <span class="ot">&lt;-</span> <span class="fu">model_to_json</span>(model)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a><span class="fu">writeLines</span>(json_config, <span class="st">&quot;model_config.json&quot;</span>)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a><span class="co"># Save weights to disk</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a><span class="fu">save_model_weights_hdf5</span>(model, <span class="st">&quot;model_weights.h5&quot;</span>)</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co"># Reload the model from the 2 files we saved</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>json_config <span class="ot">&lt;-</span> <span class="fu">readLines</span>(<span class="st">&quot;model_config.json&quot;</span>)</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>new_model <span class="ot">&lt;-</span> <span class="fu">model_from_json</span>(json_config)</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a><span class="fu">load_model_weights_hdf5</span>(new_model, <span class="st">&quot;model_weights.h5&quot;</span>)</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a><span class="co"># Check that the state is preserved</span></span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(new_model, x_test)</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a><span class="fu">all.equal</span>(predictions, new_predictions)</span></code></pre></div>
<p>Note that the optimizer was not preserved. But remember that the
simplest, recommended way is just this:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">save_model_hdf5</span>(model, <span class="st">&quot;model.h5&quot;</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>new_model <span class="ot">&lt;-</span> <span class="fu">load_model_hdf5</span>(<span class="st">&quot;model.h5&quot;</span>)</span></code></pre></div>
</div>
<div id="weights-only-saving-in-savedmodel-format" class="section level3">
<h3>Weights-only saving in SavedModel format</h3>
<p>Note that save_weights can create files either in the Keras HDF5
format, or in the TensorFlow SavedModel format.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="fu">save_model_weights_tf</span>(model, <span class="st">&quot;model_weights&quot;</span>)</span></code></pre></div>
</div>
</div>
<div id="saving-subclassed-models" class="section level2">
<h2>Saving Subclassed Models</h2>
<p>Sequential models and Functional models are data structures that
represent a DAG of layers. As such, they can be safely serialized and
deserialized.</p>
<p>A subclassed model differs in that it’s not a data structure, it’s a
piece of code. The architecture of the model is defined via the body of
the call method. This means that the architecture of the model cannot be
safely serialized. To load a model, you’ll need to have access to the
code that created it (the code of the model subclass). Alternatively,
you could be serializing this code as bytecode (e.g. via pickling), but
that’s unsafe and generally not portable.</p>
<p>For more information about these differences, see the article <a href="https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021">“What
are Symbolic and Imperative APIs in TensorFlow 2.0?”</a>.</p>
<p>Let’s consider the following subclassed model, which follows the same
structure as the model from the first section:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>keras_model_simple_mlp <span class="ot">&lt;-</span> <span class="cf">function</span>(num_classes, </span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>                                   <span class="at">use_bn =</span> <span class="cn">FALSE</span>, <span class="at">use_dp =</span> <span class="cn">FALSE</span>, </span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>                                   <span class="at">name =</span> <span class="cn">NULL</span>) {</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>  </span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>  <span class="co"># define and return a custom model</span></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>  <span class="fu">keras_model_custom</span>(<span class="at">name =</span> name, <span class="cf">function</span>(self) {</span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>    </span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>    <span class="co"># create layers we&#39;ll need for the call (this code executes once)</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a>    self<span class="sc">$</span>dense1 <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>)</span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>    self<span class="sc">$</span>dense2 <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> num_classes, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>    <span class="cf">if</span> (use_dp)</span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>      self<span class="sc">$</span>dp <span class="ot">&lt;-</span> <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.5</span>)</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>    <span class="cf">if</span> (use_bn)</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>      self<span class="sc">$</span>bn <span class="ot">&lt;-</span> <span class="fu">layer_batch_normalization</span>(<span class="at">axis =</span> <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a>    </span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a>    <span class="co"># implement call (this code executes during training &amp; inference)</span></span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a>    <span class="cf">function</span>(inputs, <span class="at">mask =</span> <span class="cn">NULL</span>) {</span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a>      x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">dense1</span>(inputs)</span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a>      <span class="cf">if</span> (use_dp)</span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a>        x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">dp</span>(x)</span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a>      <span class="cf">if</span> (use_bn)</span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a>        x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">bn</span>(x)</span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">dense2</span>(x)</span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a>    }</span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a>  })</span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a>}</span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_simple_mlp</span>(<span class="at">num_classes =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>First of all, a subclassed model that has never been used cannot be
saved.</p>
<p>That’s because a subclassed model needs to be called on some data in
order to create its weights.</p>
<p>Until the model has been called, it does not know the
<code>shape</code> and <code>dtype</code> of the input data it should be
expecting, and thus cannot create its weight variables. You may remember
that in the Functional model from the first section, the
<code>shape</code> and <code>dtype</code> of the inputs was specified in
advance (via <code>layer_input</code>) – that’s why Functional models
have a state as soon as they’re instantiated.</p>
<p>Let’s train the model, so as to give it a state:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(<span class="at">loss =</span> <span class="st">&quot;sparse_categorical_crossentropy&quot;</span>,</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>                  <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>())</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>history <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(x_train, y_train, <span class="at">batch_size =</span> <span class="dv">64</span>, <span class="at">epochs =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>The recommended way to save a subclassed model is to use
<code>save_model_weights_tf</code> to create a TensorFlow SavedModel
checkpoint, which will contain the value of all variables associated
with the model: - The layers’ weights - The optimizer’s state - Any
variables associated with stateful model metrics (if any).</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="fu">save_model_weights_tf</span>(model, <span class="st">&quot;my_weights&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co"># Save predictions for future checks</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, x_test)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="co"># Also save the loss on the first batch</span></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="co"># to later assert that the optimizer state was preserved</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>first_batch_loss <span class="ot">&lt;-</span> <span class="fu">train_on_batch</span>(model, x_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">64</span>,], y_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">64</span>])</span></code></pre></div>
<p>To restore your model, you will need access to the code that created
the model object.</p>
<p>Note that in order to restore the optimizer state and the state of
any stateful metric, you should compile the model (with the exact same
arguments as before) and call it on some data before calling
load_weights:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>new_model <span class="ot">&lt;-</span> <span class="fu">keras_model_simple_mlp</span>(<span class="at">num_classes =</span> <span class="dv">10</span>)</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a>new_model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(<span class="at">loss =</span> <span class="st">&quot;sparse_categorical_crossentropy&quot;</span>,</span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>                  <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>())</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a><span class="co"># This initializes the variables used by the optimizers,</span></span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a><span class="co"># as well as any stateful metric variables</span></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a><span class="fu">train_on_batch</span>(new_model, x_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], y_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a><span class="co"># Load the state of the old model</span></span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a><span class="fu">load_model_weights_tf</span>(new_model, <span class="st">&quot;my_weights&quot;</span>)</span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a><span class="co"># Check that the model state has been preserved</span></span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a>new_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(new_model, x_test)</span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a><span class="fu">all.equal</span>(predictions, new_predictions)</span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" tabindex="-1"></a><span class="co"># The optimizer state is preserved as well,</span></span>
<span id="cb21-17"><a href="#cb21-17" tabindex="-1"></a><span class="co"># so you can resume training where you left off</span></span>
<span id="cb21-18"><a href="#cb21-18" tabindex="-1"></a>new_first_batch_loss <span class="ot">&lt;-</span> <span class="fu">train_on_batch</span>(new_model, x_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">64</span>,], y_train[<span class="dv">1</span><span class="sc">:</span><span class="dv">64</span>])</span>
<span id="cb21-19"><a href="#cb21-19" tabindex="-1"></a>first_batch_loss <span class="sc">==</span> new_first_batch_loss</span></code></pre></div>
<p>You’ve reached the end of this guide! This covers everything you need
to know about saving and serializing models with Keras in TensorFlow
2.0.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
