<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Guide to Keras Basics</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Guide to Keras Basics</h1>



<p>Keras is a high-level API to build and train deep learning models.
Itâ€™s used for fast prototyping, advanced research, and production, with
three key advantages:</p>
<ul>
<li><em>User friendly</em><br> Keras has a simple, consistent interface
optimized for common use cases. It provides clear and actionable
feedback for user errors.</li>
<li><em>Modular and composable</em><br> Keras models are made by
connecting configurable building blocks together, with few
restrictions.</li>
<li><em>Easy to extend</em><br> Write custom building blocks to express
new ideas for research. Create new layers, loss functions, and develop
state-of-the-art models.</li>
</ul>
<div id="import-keras" class="section level2">
<h2>Import keras</h2>
<p>To get started, load the <code>keras</code> library:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(keras)</span></code></pre></div>
</div>
<div id="build-a-simple-model" class="section level2">
<h2>Build a simple model</h2>
<div id="sequential-model" class="section level3">
<h3>Sequential model</h3>
<p>In Keras, you assemble <em>layers</em> to build <em>models</em>. A
model is (usually) a graph of layers. The most common type of model is a
stack of layers: the <code>sequential</code> model.</p>
<p>To build a simple, fully-connected network (i.e., a multi-layer
perceptron):</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>  </span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>  <span class="co"># Adds a densely-connected layer with 64 units to the model:</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>  </span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>  <span class="co"># Add another:</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>  </span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>  <span class="co"># Add a softmax layer with 10 output units:</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span></code></pre></div>
</div>
<div id="configure-the-layers" class="section level3">
<h3>Configure the layers</h3>
<p>There are many <code>layers</code> available with some common
constructor parameters:</p>
<ul>
<li><code>activation</code>: Set the <a href="https://tensorflow.rstudio.com/reference/keras/#section-activation-layers">activation
function</a> for the layer. By default, no activation is applied.</li>
<li><code>kernel_initializer</code> and <code>bias_initializer</code>:
The initialization schemes that create the layerâ€™s weights (kernel and
bias). This defaults to the <a href="https://tensorflow.rstudio.com/reference/keras/initializer_glorot_uniform"><code>Glorot uniform</code></a>
initializer.</li>
<li><code>kernel_regularizer</code> and <code>bias_regularizer</code>:
The regularization schemes that apply to the layerâ€™s weights (kernel and
bias), such as L1 or L2 regularization. By default, no regularization is
applied.</li>
</ul>
<p>The following instantiates <code>dense</code> layers using
constructor arguments:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Create a sigmoid layer:</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span><span class="st">&#39;sigmoid&#39;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">kernel_regularizer =</span> <span class="fu">regularizer_l1</span>(<span class="fl">0.01</span>))</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co"># A linear layer with L2 regularization of factor 0.01 applied to the bias vector:</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">bias_regularizer =</span> <span class="fu">regularizer_l2</span>(<span class="fl">0.01</span>))</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co"># A linear layer with a kernel initialized to a random orthogonal matrix:</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">kernel_initializer =</span> <span class="st">&#39;orthogonal&#39;</span>)</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co"># A linear layer with a bias vector initialized to 2.0:</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">bias_initializer =</span> <span class="fu">initializer_constant</span>(<span class="fl">2.0</span>))</span></code></pre></div>
</div>
</div>
<div id="train-and-evaluate" class="section level2">
<h2>Train and evaluate</h2>
<div id="set-up-training" class="section level3">
<h3>Set up training</h3>
<p>After the model is constructed, configure its learning process by
calling the <code>compile</code> method:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">&#39;adam&#39;</span>,</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>)</span></code></pre></div>
<p><code>compile</code> takes three important arguments:</p>
<ul>
<li><code>optimizer</code>: This object specifies the training
procedure. Commonly used optimizers are e.g.<br />
<a href="https://tensorflow.rstudio.com/reference/keras/optimizer_adam.html"><code>adam</code></a>,
<a href="https://tensorflow.rstudio.com/reference/keras/optimizer_rmsprop.html"><code>rmsprop</code></a>,
or <a href="https://tensorflow.rstudio.com/reference/keras/optimizer_sgd.html"><code>sgd</code></a>.</li>
<li><code>loss</code>: The function to minimize during optimization.
Common choices include mean square error (<code>mse</code>),
<code>categorical_crossentropy</code>, and
<code>binary_crossentropy</code>.</li>
<li><code>metrics</code>: Used to monitor training. In classification,
this usually is accuracy.</li>
</ul>
<p>The following shows a few examples of configuring a model for
training:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Configure a model for mean-squared error regression.</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">&#39;adam&#39;</span>,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">&#39;mse&#39;</span>,           <span class="co"># mean squared error</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">&#39;mae&#39;</span>)   <span class="co"># mean absolute error</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="co"># Configure a model for categorical classification.</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>(<span class="at">lr =</span> <span class="fl">0.01</span>),</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">&quot;categorical_crossentropy&quot;</span>,</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">&quot;categorical_accuracy&quot;</span>)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="input-data" class="section level3">
<h3>Input data</h3>
<p>You can train keras models directly on R matrices and arrays
(possibly created from R <code>data.frames</code>). A model is fit to
the training data using the <code>fit</code> method:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1000</span> <span class="sc">*</span> <span class="dv">32</span>), <span class="at">nrow =</span> <span class="dv">1000</span>, <span class="at">ncol =</span> <span class="dv">32</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>labels <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1000</span> <span class="sc">*</span> <span class="dv">10</span>), <span class="at">nrow =</span> <span class="dv">1000</span>, <span class="at">ncol =</span> <span class="dv">10</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>  data,</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>  labels,</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">10</span>,</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>)</span></code></pre></div>
<p><code>fit</code> takes three important arguments:</p>
<ul>
<li><code>epochs</code>: Training is structured into <em>epochs</em>. An
epoch is one iteration over the entire input data (this is done in
smaller batches).</li>
<li><code>batch_size</code>: When passed matrix or array data, the model
slices the data into smaller batches and iterates over these batches
during training. This integer specifies the size of each batch. Be aware
that the last batch may be smaller if the total number of samples is not
divisible by the batch size.</li>
<li><code>validation_data</code>: When prototyping a model, you want to
easily monitor its performance on some validation data. Passing this
argument â€” a list of inputs and labels â€” allows the model to display the
loss and metrics in inference mode for the passed data, at the end of
each epoch.</li>
</ul>
<p>Hereâ€™s an example using <code>validation_data</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1000</span> <span class="sc">*</span> <span class="dv">32</span>), <span class="at">nrow =</span> <span class="dv">1000</span>, <span class="at">ncol =</span> <span class="dv">32</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>labels <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1000</span> <span class="sc">*</span> <span class="dv">10</span>), <span class="at">nrow =</span> <span class="dv">1000</span>, <span class="at">ncol =</span> <span class="dv">10</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>val_data <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1000</span> <span class="sc">*</span> <span class="dv">32</span>), <span class="at">nrow =</span> <span class="dv">100</span>, <span class="at">ncol =</span> <span class="dv">32</span>)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>val_labels <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="dv">10</span>), <span class="at">nrow =</span> <span class="dv">100</span>, <span class="at">ncol =</span> <span class="dv">10</span>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>  data,</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>  labels,</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">10</span>,</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>  <span class="at">validation_data =</span> <span class="fu">list</span>(val_data, val_labels)</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="evaluate-and-predict" class="section level3">
<h3>Evaluate and predict</h3>
<p>Same as <code>fit</code>, the <code>evaluate</code> and
<code>predict</code> methods can use raw R data as well as a
<code>dataset</code>.</p>
<p>To <em>evaluate</em> the inference-mode loss and metrics for the data
provided:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(test_data, test_labels, <span class="at">batch_size =</span> <span class="dv">32</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(test_dataset, <span class="at">steps =</span> <span class="dv">30</span>)</span></code></pre></div>
<p>And to <em>predict</em> the output of the last layer in inference for
the data provided, again as R data as well as a
<code>dataset</code>:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_data, <span class="at">batch_size =</span> <span class="dv">32</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    </span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">predict</span>(test_dataset, <span class="at">steps =</span> <span class="dv">30</span>)</span></code></pre></div>
</div>
</div>
<div id="build-advanced-models" class="section level2">
<h2>Build advanced models</h2>
<div id="functional-api" class="section level3">
<h3>Functional API</h3>
<p>The <code>sequential</code> model is a simple stack of layers that
cannot represent arbitrary models. Use the <a href="functional_api.html">Keras functional API</a> to build complex
model topologies such as:</p>
<ul>
<li>multi-input models,</li>
<li>multi-output models,</li>
<li>models with shared layers (the same layer called several
times),</li>
<li>models with non-sequential data flows (e.g., residual
connections).</li>
</ul>
<p>Building a model with the functional API works like this:</p>
<ol style="list-style-type: decimal">
<li>A layer instance is callable and returns a tensor.</li>
<li>Input tensors and output tensors are used to define a
<code>keras_model</code> instance.</li>
<li>This model is trained just like the <code>sequential</code>
model.</li>
</ol>
<p>The following example uses the functional API to build a simple,
fully-connected network:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>inputs <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> (<span class="dv">32</span>))  <span class="co"># Returns a placeholder tensor</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> inputs <span class="sc">%&gt;%</span> </span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co"># Instantiate the model given inputs and outputs.</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> inputs, <span class="at">outputs =</span> predictions)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co"># The compile step specifies the training configuration.</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>(<span class="at">lr =</span> <span class="fl">0.001</span>),</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>)</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a><span class="co"># Trains for 5 epochs</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>  data,</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>  labels,</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">5</span></span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="custom-layers" class="section level3">
<h3>Custom layers</h3>
<p>To create a custom Keras layer, you create an R6 class derived from
<code>KerasLayer</code>. There are three methods to implement (only one
of which, <code>call()</code>, is required for all types of layer):</p>
<ul>
<li><code>build(input_shape)</code>: This is where you will define your
weights. Note that if your layer doesnâ€™t define trainable weights then
you need not implement this method.</li>
<li><code>call(x)</code>: This is where the layerâ€™s logic lives. Unless
you want your layer to support masking, you only have to care about the
first argument passed to call: the input tensor.</li>
<li><code>compute_output_shape(input_shape)</code>: In case your layer
modifies the shape of its input, you should specify here the shape
transformation logic. This allows Keras to do automatic shape inference.
If you donâ€™t modify the shape of the input then you need not implement
this method.</li>
</ul>
<p>Here is an example custom layer that performs a matrix
multiplication:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>CustomLayer <span class="ot">&lt;-</span> R6<span class="sc">::</span><span class="fu">R6Class</span>(<span class="st">&quot;CustomLayer&quot;</span>,</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>                                  </span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>  <span class="at">inherit =</span> KerasLayer,</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>  </span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>  <span class="at">public =</span> <span class="fu">list</span>(</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>    </span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>    <span class="at">output_dim =</span> <span class="cn">NULL</span>,</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>    </span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>    <span class="at">kernel =</span> <span class="cn">NULL</span>,</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>    </span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>    <span class="at">initialize =</span> <span class="cf">function</span>(output_dim) {</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>      self<span class="sc">$</span>output_dim <span class="ot">&lt;-</span> output_dim</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>    },</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>    </span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>    <span class="at">build =</span> <span class="cf">function</span>(input_shape) {</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>      self<span class="sc">$</span>kernel <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">add_weight</span>(</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a>        <span class="at">name =</span> <span class="st">&#39;kernel&#39;</span>, </span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>        <span class="at">shape =</span> <span class="fu">list</span>(input_shape[[<span class="dv">2</span>]], self<span class="sc">$</span>output_dim),</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>        <span class="at">initializer =</span> <span class="fu">initializer_random_normal</span>(),</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>        <span class="at">trainable =</span> <span class="cn">TRUE</span></span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>      )</span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a>    },</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>    </span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>    <span class="at">call =</span> <span class="cf">function</span>(x, <span class="at">mask =</span> <span class="cn">NULL</span>) {</span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>      <span class="fu">k_dot</span>(x, self<span class="sc">$</span>kernel)</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>    },</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>    </span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a>    <span class="at">compute_output_shape =</span> <span class="cf">function</span>(input_shape) {</span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>      <span class="fu">list</span>(input_shape[[<span class="dv">1</span>]], self<span class="sc">$</span>output_dim)</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a>    }</span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a>  )</span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>)</span></code></pre></div>
<p>In order to use the custom layer within a Keras model you also need
to create a wrapper function which instantiates the layer using the
<code>create_layer()</code> function. For example:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="co"># define layer wrapper function</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>layer_custom <span class="ot">&lt;-</span> <span class="cf">function</span>(object, output_dim, <span class="at">name =</span> <span class="cn">NULL</span>, <span class="at">trainable =</span> <span class="cn">TRUE</span>) {</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>  <span class="fu">create_layer</span>(CustomLayer, object, <span class="fu">list</span>(</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>    <span class="at">output_dim =</span> <span class="fu">as.integer</span>(output_dim),</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>    <span class="at">name =</span> name,</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    <span class="at">trainable =</span> trainable</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>  ))</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>}</span></code></pre></div>
<p>You can now use the layer in a model as usual:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>model <span class="sc">%&gt;%</span> </span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">32</span>,<span class="dv">32</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>  <span class="fu">layer_custom</span>(<span class="at">output_dim =</span> <span class="dv">32</span>)</span></code></pre></div>
</div>
<div id="custom-models" class="section level3">
<h3>Custom models</h3>
<p>In addition to creating custom layers, you can also create a custom
model. This might be necessary if you wanted to use TensorFlow eager
execution in combination with an imperatively written forward pass.</p>
<p>In cases where this is not needed, but flexibility in building the
architecture is required, it is recommended to just stick with the
functional API.</p>
<p>A custom model is defined by calling
<code>keras_model_custom()</code> passing a function that specifies the
layers to be created and the operations to be executed on forward
pass.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="cf">function</span>(input_dim, output_dim, <span class="at">name =</span> <span class="cn">NULL</span>) {</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>  </span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>  <span class="co"># define and return a custom model</span></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>  <span class="fu">keras_model_custom</span>(<span class="at">name =</span> name, <span class="cf">function</span>(self) {</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>    </span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>    <span class="co"># create layers we&#39;ll need for the call (this code executes once)</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>    <span class="co"># note: the layers have to be created on the self object!</span></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>    self<span class="sc">$</span>dense1 <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>, <span class="at">input_shape =</span> input_dim)</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>    self<span class="sc">$</span>dense2 <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>)</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>    self<span class="sc">$</span>dense3 <span class="ot">&lt;-</span> <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">10</span>, <span class="at">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>    </span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>    <span class="co"># implement call (this code executes during training &amp; inference)</span></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>    <span class="cf">function</span>(inputs, <span class="at">mask =</span> <span class="cn">NULL</span>) {</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>      x <span class="ot">&lt;-</span> inputs <span class="sc">%&gt;%</span></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>        self<span class="sc">$</span><span class="fu">dense1</span>() <span class="sc">%&gt;%</span></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>        self<span class="sc">$</span><span class="fu">dense2</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>        self<span class="sc">$</span><span class="fu">dense3</span>()</span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>      x</span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>    }</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>  })</span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>}</span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">my_model</span>(<span class="at">input_dim =</span> <span class="dv">32</span>, <span class="at">output_dim =</span> <span class="dv">10</span>)</span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a></span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_rmsprop</span>(<span class="at">lr =</span> <span class="fl">0.001</span>),</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">list</span>(<span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>)</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a><span class="co"># Trains for 5 epochs</span></span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a>  data,</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a>  labels,</span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">5</span></span>
<span id="cb14-37"><a href="#cb14-37" tabindex="-1"></a>)</span></code></pre></div>
</div>
</div>
<div id="callbacks" class="section level2">
<h2>Callbacks</h2>
<p>A callback is an object passed to a model to customize and extend its
behavior during training. You can write your own custom callback, or use
the built-in <code>callbacks</code> that include:</p>
<ul>
<li><code>callback_model_checkpoint</code>: Save checkpoints of your
model at regular intervals.</li>
<li><code>callback_learning_rate_scheduler</code>: Dynamically change
the learning rate.</li>
<li><code>callback_early_stopping</code>: Interrupt training when
validation performance has stopped improving.</li>
<li><code>callbacks_tensorboard</code>: Monitor the modelâ€™s behavior
using <a href="training_visualization.html#tensorboard">TensorBoard</a>.</li>
</ul>
<p>To use a <code>callback</code>, pass it to the modelâ€™s
<code>fit</code> method:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>callbacks <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>  <span class="fu">callback_early_stopping</span>(<span class="at">patience =</span> <span class="dv">2</span>, <span class="at">monitor =</span> <span class="st">&#39;val_loss&#39;</span>),</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>  <span class="fu">callback_tensorboard</span>(<span class="at">log_dir =</span> <span class="st">&#39;./logs&#39;</span>)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>)</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>  data,</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>  labels,</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">5</span>,</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>  <span class="at">callbacks =</span> callbacks,</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>  <span class="at">validation_data =</span> <span class="fu">list</span>(val_data, val_labels)</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="save-and-restore" class="section level2">
<h2>Save and restore</h2>
<div id="weights-only" class="section level3">
<h3>Weights only</h3>
<p>Save and load the weights of a model using
<code>save_model_weights_hdf5</code> and
<code>load_model_weights_hdf5</code>, respectively:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># save in SavedModel format</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">save_model_weights_tf</span>(<span class="st">&#39;my_model/&#39;</span>)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="co"># Restore the model&#39;s state,</span></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="co"># this requires a model with the same architecture.</span></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">load_model_weights_tf</span>(<span class="st">&#39;my_model/&#39;</span>)</span></code></pre></div>
</div>
<div id="configuration-only" class="section level3">
<h3>Configuration only</h3>
<p>A modelâ€™s configuration can be saved - this serializes the model
architecture without any weights. A saved configuration can recreate and
initialize the same model, even without the code that defined the
original model. Keras supports JSON and YAML serialization formats:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># Serialize a model to JSON format</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>json_string <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">model_to_json</span>()</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="co"># Recreate the model (freshly initialized)</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>fresh_model <span class="ot">&lt;-</span> <span class="fu">model_from_json</span>(json_string)</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="co"># Serializes a model to YAML format</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>yaml_string <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">model_to_yaml</span>()</span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a><span class="co"># Recreate the model</span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>fresh_model <span class="ot">&lt;-</span> <span class="fu">model_from_yaml</span>(yaml_string)</span></code></pre></div>
<p>Caution: Custom models are not serializable because their
architecture is defined by the R code in the function passed to
<code>keras_model_custom</code>.</p>
</div>
<div id="entire-model" class="section level3">
<h3>Entire model</h3>
<p>The entire model can be saved to a file that contains the weight
values, the modelâ€™s configuration, and even the optimizerâ€™s
configuration. This allows you to checkpoint a model and resume training
later â€”from the exact same state â€”without access to the original
code.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="co"># Save entire model to the SavedModel format</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">save_model_tf</span>(<span class="st">&#39;my_model/&#39;</span>)</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="co"># Recreate the exact same model, including weights and optimizer.</span></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">load_model_tf</span>(<span class="st">&#39;my_model/&#39;</span>)</span></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
