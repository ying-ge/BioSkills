% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/crossprodSelf.R
\name{big_crossprodSelf}
\alias{big_crossprodSelf}
\alias{crossprod,FBM,missing-method}
\title{Crossprod}
\usage{
big_crossprodSelf(
  X,
  fun.scaling = big_scale(center = FALSE, scale = FALSE),
  ind.row = rows_along(X),
  ind.col = cols_along(X),
  block.size = block_size(nrow(X)),
  backingfile = tempfile(tmpdir = getOption("FBM.dir"))
)

\S4method{crossprod}{FBM,missing}(x, y)
}
\arguments{
\item{X}{An object of class \link[=FBM-class]{FBM}.}

\item{fun.scaling}{A function with parameters \code{X}, \code{ind.row} and \code{ind.col},
and that returns a data.frame with \verb{$center} and \verb{$scale} for the columns
corresponding to \code{ind.col}, to scale each of their elements such as followed:
\deqn{\frac{X_{i,j} - center_j}{scale_j}.} Default doesn't use any scaling.
You can also provide your own \code{center} and \code{scale} by using \code{\link[=as_scaling_fun]{as_scaling_fun()}}.}

\item{ind.row}{An optional vector of the row indices that are used.
If not specified, all rows are used. \strong{Don't use negative indices.}}

\item{ind.col}{An optional vector of the column indices that are used.
If not specified, all columns are used. \strong{Don't use negative indices.}}

\item{block.size}{Maximum number of columns read at once.
Default uses \link{block_size}.}

\item{backingfile}{Path to the file storing the FBM data on disk.
\strong{An extension ".bk" will be automatically added.} Default stores in the
temporary directory, which you can change using global option "FBM.dir".}

\item{x}{A 'double' FBM.}

\item{y}{Missing.}
}
\value{
A temporary \link[=FBM-class]{FBM}, with the following two attributes:
\itemize{
\item a numeric vector \code{center} of column scaling,
\item a numeric vector \code{scale} of column scaling.
}
}
\description{
Compute \eqn{X.row^T X.row} for a Filebacked Big Matrix \code{X}
after applying a particular scaling to it.
}
\section{Matrix parallelization}{

Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks. Instead, you can use
the \href{https://forum.posit.co/t/intel-mkl-integration-to-r-on-windows/176071}{MKL}
or OpenBLAS in order to accelerate these block matrix computations.
You can control the number of cores used by these optimized matrix libraries
with \code{bigparallelr::set_blas_ncores()}.
}

\examples{
X <- FBM(13, 17, init = rnorm(221))
true <- crossprod(X[])

# No scaling
K1 <- crossprod(X)
class(K1)
all.equal(K1, true)

K2 <- big_crossprodSelf(X)
class(K2)
K2$backingfile
all.equal(K2[], true)

# big_crossprodSelf() provides some scaling and subsetting
# Example using only half of the data:
n <- nrow(X)
ind <- sort(sample(n, n/2))
K3 <- big_crossprodSelf(X, fun.scaling = big_scale(), ind.row = ind)
true2 <- crossprod(scale(X[ind, ]))
all.equal(K3[], true2)
}
\seealso{
\link{crossprod}
}
