name: Download Python Packages (Ë∑≥ËøáÂ§ßÊñá‰ª∂Áâà - ‰øÆÂ§çEOF)
 
on:
  workflow_dispatch:
    inputs:
      python_version:
        description: 'Python version to use'
        required: false
        default: '3.12'
      package_file:
        description: 'Path to package list file'
        required: false
        default: '.github/docs/lib_python.txt'
  schedule:
    # ÊØèÊúà9Âè∑Ëá™Âä®Êõ¥Êñ∞
    - cron: '0 0 9 * *'
  push:
    paths:
      - '.github/docs/lib_python.txt'
      - '.github/scripts/*.py'
      
permissions:
  contents: write
  actions: read
  
jobs:
  download-packages:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ github.event.inputs.python_version || '3.12' }}
        
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles(github.event.inputs.package_file || '.github/docs/lib_python.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Create Python packages directory structure
      run: |
        mkdir -p Python_packages_backup/{singlecell,machine_learning,core,visualization,genomics,immunology,deep_learning,data_processing,uncategorized}
        
    - name: Install required tools
      run: |
        pip install wheel setuptools requests pyyaml tqdm
        
    - name: Configure Git
      run: |
        git config --global user.name "GitHub Actions Bot"
        git config --global user.email "actions@github.com"
        
    - name: Make scripts executable
      run: |
        chmod +x .github/scripts/*.py
        
    - name: Parse package list
      env:
        PYTHON_VERSION: ${{ github.event.inputs.python_version || '3.12' }}
      run: |
        python .github/scripts/parse_packages.py \
          "${{ github.event.inputs.package_file || '.github/docs/lib_python.txt' }}" \
          classified_packages.yml
          
    - name: Create download script
      run: |
        cat > incremental_download.py << 'EOF'
        import os
        import sys
        import yaml
        import json
        import time
        import subprocess
        import shutil
        from pathlib import Path
        from tqdm import tqdm
        
        def write_progress(package_name, status, size_mb=0, category="", reason=""):
            progress_info = f"{package_name}|{status}|{size_mb}|{category}|{reason}"
            with open("download_progress.txt", "w") as f:
                f.write(progress_info)
            if reason:
                print(f"üì¶ ËøõÂ∫¶Êõ¥Êñ∞: {package_name} - {status} ({size_mb}MB) - {reason}")
            else:
                print(f"üì¶ ËøõÂ∫¶Êõ¥Êñ∞: {package_name} - {status} ({size_mb}MB)")
        
        def get_package_info_before_download(package_name):
            try:
                result = subprocess.run(['pip', 'show', package_name], 
                                      capture_output=True, text=True, timeout=30)
                if result.returncode == 0:
                    lines = result.stdout.split('\n')
                    for line in lines:
                        if line.startswith('Size:'):
                            size_str = line.split(':', 1)[1].strip()
                            if 'KB' in size_str:
                                size_kb = float(size_str.replace('KB', '').strip())
                                return size_kb / 1024
                            elif 'MB' in size_str:
                                return float(size_str.replace('MB', '').strip())
            except:
                pass
            return None
        
        def check_file_sizes(package_dir, max_size_mb=100):
            large_files = []
            total_size = 0
            
            for root, dirs, files in os.walk(package_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    if os.path.isfile(file_path):
                        file_size = os.path.getsize(file_path)
                        file_size_mb = file_size / (1024 * 1024)
                        total_size += file_size_mb
                        
                        if file_size_mb > max_size_mb:
                            large_files.append({
                                'name': file,
                                'size_mb': round(file_size_mb, 2)
                            })
            
            return large_files, round(total_size, 2)
        
        def download_single_package(package_info, backup_dir, max_size_mb=100):
            package_name = package_info['name']
            category = package_info.get('category', 'uncategorized')
            
            estimated_size = get_package_info_before_download(package_name)
            if estimated_size and estimated_size > max_size_mb:
                write_progress(package_name, 'skipped_estimated_large', estimated_size, category, 
                             f"È¢Ñ‰º∞Â§ßÂ∞è: {estimated_size:.1f}MB")
                return False, 0, None
            
            category_dir = os.path.join(backup_dir, category)
            os.makedirs(category_dir, exist_ok=True)
            
            package_dir = os.path.join(category_dir, package_name)
            
            if os.path.exists(package_dir):
                shutil.rmtree(package_dir)
            os.makedirs(package_dir)
            
            try:
                cmd = [
                    'pip', 'download', '--no-deps', '--dest', package_dir, package_name
                ]
                
                print(f"üîÑ Ê≠£Âú®‰∏ãËΩΩ {package_name}...")
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                
                if result.returncode == 0:
                    files = os.listdir(package_dir)
                    if files:
                        large_files, total_size = check_file_sizes(package_dir, max_size_mb)
                        
                        if large_files:
                            large_files_info = ", ".join([f"{f['name']}({f['size_mb']}MB)" for f in large_files])
                            write_progress(package_name, 'skipped_large_files', total_size, category, 
                                         f"Â§ßÊñá‰ª∂: {large_files_info}")
                            
                            shutil.rmtree(package_dir)
                            return False, 0, None
                        else:
                            info = {
                                'name': package_name,
                                'category': category,
                                'download_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                                'files': files,
                                'size_mb': total_size,
                                'status': 'success',
                                'estimated_size': estimated_size
                            }
                            
                            with open(os.path.join(package_dir, 'package_info.json'), 'w') as f:
                                json.dump(info, f, indent=2)
                            
                            write_progress(package_name, 'success', total_size, category)
                            return True, total_size, package_dir
                    else:
                        write_progress(package_name, 'failed_no_files', 0, category, "‰∏ãËΩΩÂêéÊó†Êñá‰ª∂")
                        return False, 0, None
                else:
                    error_msg = result.stderr.strip() if result.stderr else f"ÈÄÄÂá∫Á†Å: {result.returncode}"
                    write_progress(package_name, 'failed_download', 0, category, error_msg[:50])
                    return False, 0, None
                    
            except subprocess.TimeoutExpired:
                write_progress(package_name, 'timeout', 0, category, "‰∏ãËΩΩË∂ÖÊó∂(300s)")
                return False, 0, None
            except Exception as e:
                write_progress(package_name, 'error', 0, category, str(e)[:50])
                return False, 0, None
        
        def main():
            if len(sys.argv) < 3:
                print("Áî®Ê≥ï: python incremental_download.py <classified_packages.yml> <backup_dir> [max_size_mb]")
                sys.exit(1)
            
            packages_file = sys.argv[1]
            backup_dir = sys.argv[2]
            max_size_mb = float(sys.argv[3]) if len(sys.argv) > 3 else 100.0
            
            with open(packages_file, 'r', encoding='utf-8') as f:
                classified_packages = yaml.safe_load(f)
            
            all_packages = []
            for category, packages in classified_packages.items():
                for package in packages:
                    all_packages.append({
                        'name': package,
                        'category': category
                    })
            
            print(f"ÂºÄÂßã‰∏ãËΩΩ {len(all_packages)} ‰∏™PythonÂåÖ (Êñá‰ª∂Â§ßÂ∞èÈôêÂà∂: {max_size_mb}MB)...")
            
            success_count = 0
            failed_count = 0
            skipped_count = 0
            total_size = 0
            
            known_large_packages = ['torch', 'tensorflow', 'jax', 'paddlepaddle', 'mxnet']
            filtered_packages = []
            
            for pkg_info in all_packages:
                if pkg_info['name'].lower() in known_large_packages:
                    write_progress(pkg_info['name'], 'skipped_known_large', 0, pkg_info['category'], 
                                 "Â∑≤Áü•Â§ßÂåÖ(>100MB)")
                    skipped_count += 1
                else:
                    filtered_packages.append(pkg_info)
            
            print(f"Ë∑≥Ëøá {len(all_packages) - len(filtered_packages)} ‰∏™Â∑≤Áü•Â§ßÂåÖÔºåÂâ©‰Ωô {len(filtered_packages)} ‰∏™ÂåÖ")
            
            for i, package_info in enumerate(tqdm(filtered_packages, desc="‰∏ãËΩΩËøõÂ∫¶")):
                success, size_mb, package_dir = download_single_package(package_info, backup_dir, max_size_mb)
                
                if success:
                    success_count += 1
                    total_size += size_mb
                elif size_mb > 0:
                    skipped_count += 1
                else:
                    failed_count += 1
                
                time.sleep(0.5)
            
            summary = {
                'total_packages': len(all_packages),
                'success_count': success_count,
                'failed_count': failed_count,
                'skipped_count': skipped_count,
                'total_size_mb': round(total_size, 2),
                'max_file_size_mb': max_size_mb,
                'completion_time': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            with open('download_summary.json', 'w') as f:
                json.dump(summary, f, indent=2)
            
            print(f"\n=== ‰∏ãËΩΩÂÆåÊàê ===")
            print(f"‚úÖ ÊàêÂäü: {success_count}")
            print(f"‚ö†Ô∏è Ë∑≥Ëøá(>100MB): {skipped_count}")
            print(f"‚ùå Â§±Ë¥•: {failed_count}")
            print(f"üíæ ÊÄªÂ§ßÂ∞è: {total_size:.2f} MB")
            print(f"üì¶ Â§ÑÁêÜÊÄªÊï∞: {len(all_packages)}")
            
        if __name__ == '__main__':
            main()
        EOF
        
    - name: Download packages with size filter
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_RUN_STARTED_AT: ${{ github.run_started_at }}
        PYTHON_VERSION: ${{ github.event.inputs.python_version || '3.12' }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_REPOSITORY: ${{ github.repository }}
        PACKAGE_FILE: ${{ github.event.inputs.package_file || '.github/docs/lib_python.txt' }}
        MAX_FILE_SIZE_MB: 100
      run: |
        # ÊµãËØïPythonËÑöÊú¨ËØ≠Ê≥ï
        echo "üß™ ÊµãËØïPythonËÑöÊú¨ËØ≠Ê≥ï..."
        python -m py_compile incremental_download.py
        if [ $? -eq 0 ]; then
            echo "‚úÖ PythonËÑöÊú¨ËØ≠Ê≥ïÊ≠£Á°Æ"
        else
            echo "‚ùå PythonËÑöÊú¨ËØ≠Ê≥ïÈîôËØØ"
            exit 1
        fi
        
        # Âú®ÂêéÂè∞ËøêË°å‰∏ãËΩΩËÑöÊú¨
        echo "üöÄ ÂºÄÂßãÈÄê‰∏™‰∏ãËΩΩPythonÂåÖ..."
        python incremental_download.py classified_packages.yml Python_packages_backup $MAX_FILE_SIZE_MB &
        download_pid=$!
        
        # ÁõëÊéßËøõÂ∫¶Âπ∂ÈÄê‰∏ÄÊèê‰∫§
        echo "üîÑ ÁõëÊéß‰∏ãËΩΩËøõÂ∫¶Âπ∂ÂÆûÊó∂Êé®ÈÄÅ..."
        last_progress=""
        commit_count=0
        
        while kill -0 $download_pid 2>/dev/null; do
          if [ -f "download_progress.txt" ]; then
            current_progress=$(cat download_progress.txt 2>/dev/null || echo "")
            
            if [ "$current_progress" != "$last_progress" ] && [ -n "$current_progress" ]; then
              package_name=$(echo "$current_progress" | cut -d'|' -f1)
              status=$(echo "$current_progress" | cut -d'|' -f2)
              size=$(echo "$current_progress" | cut -d'|' -f3)
              category=$(echo "$current_progress" | cut -d'|' -f4)
              reason=$(echo "$current_progress" | cut -d'|' -f5)
              
              echo "üì¶ ÂåÖÂ§ÑÁêÜÂÆåÊàê: $package_name ($status, ${size}MB)"
              if [ -n "$reason" ]; then
                echo "   ÂéüÂõ†: $reason"
              fi
              
              if [ "$status" = "success" ]; then
                package_path="Python_packages_backup/${category}/${package_name}"
                
                if [ -d "$package_path" ]; then
                  echo "üíæ Êèê‰∫§Âπ∂Êé®ÈÄÅ $package_name..."
                  
                  git add "$package_path/"
                  git add download_progress.txt 2>/dev/null || true
                  
                  commit_msg="üì¶ Add ${package_name} (${size}MB) [${category}] - $(date +'%m-%d %H:%M')"
                  if git commit -m "$commit_msg"; then
                    echo "üöÄ Êé®ÈÄÅ‰∏≠..."
                    
                    retry=0
                    while [ $retry -lt 3 ]; do
                      if git push origin main; then
                        echo "‚úÖ $package_name Êé®ÈÄÅÊàêÂäü"
                        commit_count=$((commit_count + 1))
                        break
                      else
                        retry=$((retry + 1))
                        echo "‚ö†Ô∏è Êé®ÈÄÅÂ§±Ë¥•ÔºåÈáçËØï $retry/3..."
                        sleep $((retry * 2))
                      fi
                    done
                    
                    if [ $retry -eq 3 ]; then
                      echo "‚ùå $package_name Êé®ÈÄÅÂ§±Ë¥•ÔºåÁªßÁª≠‰∏ã‰∏Ä‰∏™..."
                    fi
                  else
                    echo "‚ùå $package_name Êèê‰∫§Â§±Ë¥•ÔºåÂèØËÉΩÊòØÁ©∫Êèê‰∫§"
                  fi
                  
                  sleep 2
                else
                  echo "‚ö†Ô∏è ÂåÖÁõÆÂΩï‰∏çÂ≠òÂú®: $package_path"
                fi
              elif [[ "$status" == *"skipped"* ]]; then
                echo "‚ö†Ô∏è Ë∑≥ËøáÂ§ßÊñá‰ª∂ÂåÖ: $package_name"
              fi
              
              last_progress="$current_progress"
            fi
          fi
          
          sleep 3
        done
        
        wait $download_pid
        echo "üéâ ‰∏ãËΩΩËÑöÊú¨ÊâßË°åÂÆåÊàê"
        
        echo "üìä ÊâßË°åÊúÄÁªàÊèê‰∫§..."
        
        git add Python_packages_backup/ 2>/dev/null || true
        git add download_summary.json 2>/dev/null || true
        
        if ! git diff --staged --quiet; then
          git commit -m "üìä Final backup cleanup - $(date +'%Y-%m-%d %H:%M')" 2>/dev/null || true
          git push origin main 2>/dev/null || true
        fi
        
        echo "‚úÖ ÊÄªËÆ°Êèê‰∫§‰∫Ü $commit_count ‰∏™ÊàêÂäüÁöÑÂåÖ"
        
    - name: Create metadata and reports
      env:
        PYTHON_VERSION: ${{ github.event.inputs.python_version || '3.12' }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
        GITHUB_RUN_ID: ${{ github.run_id }}
        GITHUB_REPOSITORY: ${{ github.repository }}
        PACKAGE_FILE: ${{ github.event.inputs.package_file || '.github/docs/lib_python.txt' }}
      run: |
        python .github/scripts/create_metadata.py \
          classified_packages.yml \
          Python_packages_backup
          
    - name: Show final summary
      if: always()
      run: |
        echo "## üìä PythonÂåÖÂ§á‰ªΩÁªìÊûú - $(date +'%Y-%m-%d %H:%M')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "download_summary.json" ]; then
          python3 << 'EOF'
          import json
          
          try:
              with open('download_summary.json', 'r') as f:
                  summary = json.load(f)
              
              print(f"| ‚úÖ ÊàêÂäü | {summary['success_count']} | Â∑≤‰∏ãËΩΩÂπ∂Êé®ÈÄÅ |")
              print(f"| ‚ö†Ô∏è Ë∑≥Ëøá(>100MB) | {summary['skipped_count']} | Êñá‰ª∂Â§ßÂ∞èË∂ÖÈôê |")
              print(f"| ‚ùå Â§±Ë¥• | {summary['failed_count']} | ‰∏ãËΩΩÂ§±Ë¥• |")
              print(f"| üì¶ ÊÄªÊï∞ | {summary['total_packages']} | ËÆ°Âàí‰∏ãËΩΩ |")
              print(f"| üíæ ÊÄªÂ§ßÂ∞è | {summary['total_size_mb']}MB | ÂÆûÈôÖÊé®ÈÄÅÊï∞ÊçÆ |")
              print(f"| ‚è∞ ÂÆåÊàêÊó∂Èó¥ | {summary['completion_time']} | Â§á‰ªΩÂÆåÊàêÊó∂Èó¥ |")
          except Exception as e:
              print(f"‚ùå Êó†Ê≥ïËØªÂèñÁªüËÆ°‰ø°ÊÅØ: {e}")
          EOF >> $GITHUB_STEP_SUMMARY
        else
          echo "| Áä∂ÊÄÅ | Êï∞Èáè | Â§áÊ≥® |" >> $GITHUB_STEP_SUMMARY
          echo "|------|------|------|" >> $GITHUB_STEP_SUMMARY
          echo "| ‚ùå Êú™Áü• | Êú™Áü• | ÁªüËÆ°Êñá‰ª∂‰∏çÂ≠òÂú® |" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üîß ÊäÄÊúØÁªÜËäÇ" >> $GITHUB_STEP_SUMMARY
        echo "- Ëá™Âä®Ë∑≥ËøáË∂ÖËøá100MBÁöÑÊñá‰ª∂" >> $GITHUB_STEP_SUMMARY
        echo "- È¢ÑÊ£ÄÊü•Â∑≤Áü•Â§ßÂåÖ(torch, tensorflowÁ≠â)" >> $GITHUB_STEP_SUMMARY
        echo "- ÈÄê‰∏™‰∏ãËΩΩÊé®ÈÄÅÔºåÈÅøÂÖçÊñá‰ª∂Á¥ØÁßØ" >> $GITHUB_STEP_SUMMARY
        echo "- Ëá™Âä®ÈáçËØïÊé®ÈÄÅÂ§±Ë¥•ÁöÑÊÉÖÂÜµ" >> $GITHUB_STEP_SUMMARY
        echo "- ÂÆûÊó∂ÁõëÊéß‰∏ãËΩΩËøõÂ∫¶" >> $GITHUB_STEP_SUMMARY
        
        if [ -d "Python_packages_backup" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìÅ Â§á‰ªΩÁõÆÂΩïÁä∂ÊÄÅ" >> $GITHUB_STEP_SUMMARY
          echo "- ÂàÜÁ±ªÁõÆÂΩïÊï∞: $(find Python_packages_backup -maxdepth 1 -type d | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "- ÂåÖÁõÆÂΩïÊï∞: $(find Python_packages_backup -mindepth 2 -maxdepth 2 -type d | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "- Êñá‰ª∂ÊÄªÊï∞: $(find Python_packages_backup -type f | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "- Á£ÅÁõò‰ΩøÁî®: $(du -sh Python_packages_backup 2>/dev/null | cut -f1 || echo 'Êú™Áü•')" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "download_progress.txt" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ‚ö†Ô∏è Ë∑≥ËøáÁöÑÂ§ßÊñá‰ª∂ÂåÖ (>100MB)" >> $GITHUB_STEP_SUMMARY
          echo "| ÂåÖÂêç | ÂéüÂõ† |" >> $GITHUB_STEP_SUMMARY
          echo "|------|------|" >> $GITHUB_STEP_SUMMARY
          
          python3 << 'EOF'
          try:
              with open('download_progress.txt', 'r') as f:
                  content = f.read().strip()
                  if content:
                      parts = content.split('|')
                      if len(parts) >= 5:
                          package_name = parts[0]
                          status = parts[1]
                          reason = parts[4]
                          if 'skipped' in status or 'known_large' in status:
                              print(f"| {package_name} | {reason} |")
          except:
              pass
          EOF >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: Create release (manual only)
      if: github.event_name == 'workflow_dispatch'
      uses: softprops/action-gh-release@v1
      with:
        tag_name: python-packages-$(date +'%Y%m%d-%H%M')
        name: Python Packages Backup $(date +'%Y-%m-%d %H:%M')
        body_path: Python_packages_backup/download_report.md
        files: |
          Python_packages_backup/**/*
        draft: false
        prerelease: false
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
